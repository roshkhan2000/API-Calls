import os
import requests
import pandas as pd
from datetime import datetime, timedelta
from io import BytesIO
from zipfile import ZipFile
from dotenv import load_dotenv
import json

load_dotenv()

API_URL = os.getenv("ZIP_API_URL")
API_KEY = os.getenv("API_KEY")

end_date = datetime.utcnow().date() - timedelta(days=1)
start_date = end_date - timedelta(days=6)

response = requests.get(API_URL, headers={"Authorization": f"Bearer {API_KEY}"})
if response.status_code != 200:
    print(f"API request failed: {response.status_code}")
    exit()

zip_bytes = BytesIO(response.content)

all_dfs = []

with ZipFile(zip_bytes) as z:
    for file_name in z.namelist():
        if file_name.endswith(".csv"):
            with z.open(file_name) as f:
                df = pd.read_csv(f)
                all_dfs.append(df)

if not all_dfs:
    print("No CSV files found in zip")
    exit()

data = pd.concat(all_dfs, ignore_index=True)

data["order_date"] = pd.to_datetime(data["order_date"], errors="coerce")
data = data[(data["order_date"].notna()) & (data["quantity"] > 0)]
data["product_name"] = data["product_name"].str.strip().str.title()
data["total_value"] = data["quantity"] * data["unit_price"]
data["weekday"] = data["order_date"].dt.day_name()

data = data[(data["order_date"].dt.date >= start_date) & (data["order_date"].dt.date <= end_date)]

summary = (
    data.groupby(["order_date", "product_name"])
    .agg(
        total_orders=("order_id", "count"),
        total_quantity=("quantity", "sum"),
        total_revenue=("total_value", "sum")
    )
    .reset_index()
)

output_file = f"weekly_product_summary_{start_date}_{end_date}.jsonl"
with open(output_file, "w", encoding="utf-8") as f:
    for _, row in summary.iterrows():
        f.write(json.dumps(row.to_dict()) + "\n")

print(f"Saved summary to {output_file}")
